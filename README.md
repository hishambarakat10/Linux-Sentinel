# Linux Sentinel
A lightweight RAG + Prompt Injection-Protected Chatbot + Web Scrapper for Linux Commands

Linux Sentinel is an intelligent chatbot designed to help users understand Linux commands easily and safely.
It reads commands and explanations from a trusted PDF, and uses Retrieval-Augmented Generation (RAG) combined with prompt injection defense to ensure accurate and secure answers.

The model retrieves the correct Linux command information based on user queries and blocks unrelated or malicious prompts, maintaining the chatbot's focus purely on Linux topics.

Features
üìÑ PDF Command Reader: Parses a PDF containing Linux commands and descriptions.

üß† RAG Framework: Retrieves the most relevant command information for any user query.

üõ°Ô∏è Prompt Injection Protection: Detects and prevents malicious or off-topic prompts.

‚ö° Fast, Lightweight: Designed to run locally or in small VMs with minimal setup.

üêß Linux-Focused: Only answers about Linux commands ‚Äî nothing else.

How It Works
Extracts all commands and explanations from a Linux Commands PDF.

Embeds the extracted data into an internal retriever.

When a user asks a question, the system retrieves the best matching command(s).

The chatbot answers strictly based on the retrieved content, rejecting unrelated requests.

**How to Run the Chatbot**
First thing to do is clone the repository from the GitHub using these steps:
1. In a terminal (Command Prompt or PowerShell) type 
git clone https://github.com/hishambarakat10/Linux-Sentinel.git
Second, we need a collection of Linux commands to work with. To gather these, we'll run Webscraper.py in VS Code from the cloned GitHub repository, which will search the web for Linux commands and save them into a PDF file named linux_commands.pdf.
(NOTICE: Make sure file path for files are correct in both webscraper.py and FlaskInstance.py)
Next, you‚Äôll need to load the Linux commands you previously web scraped using the earlier web scraping program.
We will now run ImportFile.py from the command line (make sure you're in the correct directory). This script processes the PDF generated by the web scraper after running run ImportFile.py.



Running ImportFile.py will create a .txt file in the same directory. This text file will be used by the embedding model to generate vectors necessary for the chatbot to operate.
After completing this step, you can run FlaskInstance.py, which will launch the web application. Visit http://127.0.0.1:5000 in your browser to access it.
Make sure to have Ollama and llama3 installed on your device to ensure the chatbot works properly refer to the Ollama website to install these on your device.
